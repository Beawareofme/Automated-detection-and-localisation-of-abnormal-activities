{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a55c9193-1fc2-4b97-9509-0eeafa4e3af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ed75eb40-0bb6-4abd-b756-18968577b3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load test features\n",
    "y_speed_test = torch.tensor(np.load(\"y_speed_feature_test.npy\"), dtype=torch.float32)  # (N, D)\n",
    "y_ang_test = torch.tensor(np.load(\"y_ang_features_test.npy\"), dtype=torch.float32)      # (N, D)\n",
    "y_bkg_test = torch.tensor(np.load(\"y_bkg_features_test.npy\"), dtype=torch.float32)      # (N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8dedd507-713e-4cd1-83b4-3fc5dbbb1f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stack motion features: shape (N, 3D)\n",
    "test_features = torch.cat([y_speed_test, y_ang_test, y_bkg_test], dim=1)\n",
    "\n",
    "# Load exemplar features: shape (M, 3D)\n",
    "exemplars = torch.tensor(np.load(\"exemplar_motion_features.npy\"), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a4212aaa-a76e-42d3-acf2-d597623a7065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get dimensions\n",
    "D = y_speed_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1d031a6e-486e-4233-b663-d070c15ae6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalization factors (from validation)\n",
    "Z_speed = torch.max(torch.cdist(y_speed_test, y_speed_test)).item()\n",
    "Z_ang = torch.max(torch.cdist(y_ang_test, y_ang_test)).item()\n",
    "Z_bkg = torch.max(torch.cdist(y_bkg_test, y_bkg_test)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "80384246-aba7-44a3-8b52-30a3f864ce32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Z_speed = Z_speed if Z_speed > 0 else 1\n",
    "Z_ang = Z_ang if Z_ang > 0 else 1\n",
    "Z_bkg = Z_bkg if Z_bkg > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9ca7f158-7d4d-4cd7-be87-ced7999df2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split exemplar features\n",
    "ex_speed = exemplars[:, :D]\n",
    "ex_ang = exemplars[:, D:2*D]\n",
    "ex_bkg = exemplars[:, 2*D:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "96747ba1-5929-49b5-aa94-936855ff0a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split test features\n",
    "te_speed = test_features[:, :D]\n",
    "te_ang = test_features[:, D:2*D]\n",
    "te_bkg = test_features[:, 2*D:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "58fee717-d263-4516-95b3-9676eb4ae11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute pairwise distances for each component: shape (N_test, N_exemplars)\n",
    "d_speed = torch.cdist(te_speed, ex_speed) / Z_speed\n",
    "d_ang   = torch.cdist(te_ang, ex_ang) / Z_ang\n",
    "d_bkg   = torch.cdist(te_bkg, ex_bkg) / Z_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c7afd55d-5401-45e9-9792-b8d58488e7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Total distance = sum of normalized distances\n",
    "total_dist = d_speed + d_ang + d_bkg  # Shape: (N_test, N_exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a3b76fb6-e7c1-4aca-93e7-cb9519118a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get minimum distance to any exemplar = anomaly score\n",
    "anomaly_scores = torch.min(total_dist, dim=1).values.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3e87203c-506b-4309-bfa2-2d643ddeb392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved anomaly scores for 13880 test volumes.\n",
      "Score stats: min = 0.3804205 max = 1.5737062 mean = 0.7931127\n"
     ]
    }
   ],
   "source": [
    "# Save anomaly scores\n",
    "np.save(\"anomaly_scores.npy\", anomaly_scores)\n",
    "print(f\"Saved anomaly scores for {len(anomaly_scores)} test volumes.\")\n",
    "print(\"Score stats: min =\", np.min(anomaly_scores), \"max =\", np.max(anomaly_scores), \"mean =\", np.mean(anomaly_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee117a-d36a-428c-aa8d-fa141ad9cb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fea70-b17b-445b-b305-47737ef6a60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1702f6-1b4b-4dc5-babe-ab6b491ae36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b5f11f65-c2d6-4ff9-95e3-9a22e4c2cc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === STEP 2: Create heatmap === #\n",
    "\n",
    "patch_size = 128\n",
    "volume_depth = 10\n",
    "stride_t = 10\n",
    "stride_h = patch_size\n",
    "stride_w = patch_size\n",
    "\n",
    "def get_video_shape(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Could not open video file.\")\n",
    "    frame_count = 0\n",
    "    frame_height = frame_width = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_height is None:\n",
    "            frame_height, frame_width = frame.shape[:2]\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    return (frame_count, frame_height, frame_width)\n",
    "\n",
    "def create_anomaly_heatmap(video_path, anomaly_scores_path, save_path):\n",
    "    T, H, W = get_video_shape(video_path)\n",
    "    print(f\"Detected video shape: {T} frames of size {H}x{W}\")\n",
    "    anomaly_scores = np.load(anomaly_scores_path)\n",
    "    print(f\"Loaded anomaly scores: {anomaly_scores.shape}\")\n",
    "\n",
    "    heatmap = np.zeros((T, H, W), dtype=np.float32)\n",
    "    volume_index = 0\n",
    "    for t in range(0, T - volume_depth + 1, stride_t):\n",
    "        for y in range(0, H - patch_size + 1, stride_h):\n",
    "            for x in range(0, W - patch_size + 1, stride_w):\n",
    "                if volume_index >= len(anomaly_scores):\n",
    "                    continue\n",
    "                score = anomaly_scores[volume_index]\n",
    "                volume_index += 1\n",
    "                for dt in range(volume_depth):\n",
    "                    frame_idx = t + dt\n",
    "                    heatmap[frame_idx, y:y+patch_size, x:x+patch_size] = np.maximum(\n",
    "                        heatmap[frame_idx, y:y+patch_size, x:x+patch_size],\n",
    "                        score\n",
    "                    )\n",
    "    np.save(save_path, heatmap)\n",
    "    print(f\"Saved anomaly heatmap to {save_path} with shape {heatmap.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "eed1b657-6710-4d31-9c89-d9127d8ac610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === STEP 3: Overlay visualization === #\n",
    "\n",
    "def overlay_binary_heatmap(video_path, heatmap_path, output_dir, threshold=0.9, alpha=0.5):\n",
    "    heatmap = np.load(heatmap_path)\n",
    "    T, H, W = heatmap.shape\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Could not open video file.\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    patch_size = 128\n",
    "    frame_idx = 0\n",
    "    BLUE = np.array([255, 0, 0], dtype=np.uint8)\n",
    "    DARK_RED = np.array([0, 0, 139], dtype=np.uint8)\n",
    "\n",
    "    while frame_idx < T:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (W, H))\n",
    "        raw_map = heatmap[frame_idx]\n",
    "        color_map = np.ones((H, W, 3), dtype=np.uint8) * BLUE\n",
    "\n",
    "        for y in range(0, H, patch_size):\n",
    "            for x in range(0, W, patch_size):\n",
    "                patch = raw_map[y:y+patch_size, x:x+patch_size]\n",
    "                if patch.max() > threshold:\n",
    "                    color_map[y:y+patch_size, x:x+patch_size] = DARK_RED\n",
    "\n",
    "        blended = cv2.addWeighted(frame, 1 - alpha, color_map, alpha, 0)\n",
    "        out_path = os.path.join(output_dir, f\"frame_{frame_idx:04d}.jpg\")\n",
    "        cv2.imwrite(out_path, blended)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"âœ… Saved refined binary overlay frames to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f91d7cd0-3620-40cc-bc9c-ae304f2eec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === STEP 4: Convert to video === #\n",
    "\n",
    "def frames_to_video(frames_dir, output_video_path, fps=25):\n",
    "    frame_files = sorted([f for f in os.listdir(frames_dir) if f.endswith(\".jpg\")])\n",
    "    if not frame_files:\n",
    "        raise ValueError(\"No .jpg frames found in the given directory.\")\n",
    "    first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))\n",
    "    height, width, _ = first_frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    for file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(frames_dir, file))\n",
    "        video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "    print(f\"âœ… Final video saved at: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "230fc345-8a9b-4f20-a5f1-f764bfc56f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected video shape: 1007 frames of size 360x640\n",
      "Loaded anomaly scores: (13880,)\n",
      "Saved anomaly heatmap to anomaly_heatmap.npy with shape (1007, 360, 640)\n",
      "âœ… Saved refined binary overlay frames to: overlay_frames\n",
      "âœ… Final video saved at: anomaly_overlay_output.mp4\n"
     ]
    }
   ],
   "source": [
    "# === RUN EVERYTHING === #\n",
    "\n",
    "video_path = \"C:\\\\Users\\\\hci\\\\Desktop\\\\data_test\\\\05.avi\"\n",
    "anomaly_scores_path = \"anomaly_scores.npy\"\n",
    "heatmap_path = \"anomaly_heatmap.npy\"\n",
    "overlay_dir = \"overlay_frames\"\n",
    "output_video_path = \"anomaly_overlay_output.mp4\"\n",
    "\n",
    "create_anomaly_heatmap(video_path, anomaly_scores_path, heatmap_path)\n",
    "overlay_binary_heatmap(video_path, heatmap_path, overlay_dir, threshold=0.9)\n",
    "frames_to_video(overlay_dir, output_video_path, fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eda94f-517b-411f-a339-b84695642855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc77ef-9ce4-41bd-86ef-ec598730e907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
